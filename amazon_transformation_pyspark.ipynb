{"cells": [{"cell_type": "markdown", "id": "1b0fb5d4-4879-46e4-8f47-23b93f06e7df", "metadata": {}, "source": "## Pyspark script for data transformation"}, {"cell_type": "code", "execution_count": 1, "id": "86ee6934-b918-4ad8-8c40-072dc2520779", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/11/19 10:56:37 INFO SparkEnv: Registering MapOutputTracker\n24/11/19 10:56:37 INFO SparkEnv: Registering BlockManagerMaster\n24/11/19 10:56:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n24/11/19 10:56:37 INFO SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\n\n# Initialize Spark session with GCS configurations\nspark = SparkSession.builder \\\n    .appName(\"AccessGCSData\") \\\n    .config(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n    .config(\"spark.hadoop.fs.gs.auth.service.account.enable\", \"true\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "891fd1d4-365c-4d1a-b0a2-734d717f6a6f", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "3.5.1\n"}], "source": "# Print Spark session to verify\nprint(spark.version)"}, {"cell_type": "code", "execution_count": 3, "id": "1d59f929-1574-4b0d-9807-8c4bbf2e4534", "metadata": {"tags": []}, "outputs": [], "source": "gcs_path = 'gs://amazon-data-analysis/amazon.csv'"}, {"cell_type": "code", "execution_count": 27, "id": "01599b95-f8d5-46a0-a783-26e66ad88a27", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df = spark.read.csv(gcs_path, header = True, inferSchema = True)"}, {"cell_type": "code", "execution_count": 28, "id": "f1cec183-378d-47fb-b0b9-9d1fad72aa0d", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- product_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- category: string (nullable = true)\n |-- _c3: string (nullable = true)\n |-- discounted_price: string (nullable = true)\n |-- actual_price: string (nullable = true)\n |-- discount_percentage: string (nullable = true)\n |-- rating: string (nullable = true)\n |-- rating_count: string (nullable = true)\n |-- about_product: string (nullable = true)\n |-- user_id: string (nullable = true)\n |-- user_name: string (nullable = true)\n |-- review_id: string (nullable = true)\n |-- review_title: string (nullable = true)\n |-- review_content: string (nullable = true)\n |-- img_link: string (nullable = true)\n |-- product_link: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 29, "id": "39ca27c9-538f-42ef-8edc-b302dc0ba99b", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 19:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+------------+--------+-------+----------------+------------+-------------------+-------+------------+-------------+-------+---------+---------+------------+--------------+--------+------------+\n|product_id|product_name|category|    _c3|discounted_price|actual_price|discount_percentage| rating|rating_count|about_product|user_id|user_name|review_id|review_title|review_content|img_link|product_link|\n+----------+------------+--------+-------+----------------+------------+-------------------+-------+------------+-------------+-------+---------+---------+------------+--------------+--------+------------+\n|         0|     2585908| 2585908|2587316|         2585911|     2585912|            2585924|2585917|     2585923|      2585917|2585911|  2585908|  2585908|     2585908|       2585908| 2585908|     2585908|\n+----------+------------+--------+-------+----------------+------------+-------------------+-------+------------+-------------+-------+---------+---------+------------+--------------+--------+------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql import functions as F\n\n# Get the count of null values for each column in the DataFrame\nnull_counts = df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n\n# Show the null counts\nnull_counts.show()\n"}, {"cell_type": "code", "execution_count": 30, "id": "ad069252-8f76-4dbd-997c-eee94cbd9f0e", "metadata": {"tags": []}, "outputs": [], "source": "# Drop the column 'Unnamed: 3' from the DataFrame\ndf = df.drop('_c3')\n\n# Show the resulting DataFrame\n#df.show()"}, {"cell_type": "code", "execution_count": 31, "id": "3ea68ceb-7b08-4cbb-9eab-11bf448e6120", "metadata": {"tags": []}, "outputs": [], "source": "df = df.dropna()"}, {"cell_type": "code", "execution_count": 32, "id": "c07038a6-ac1c-4bc3-b3f9-763324c62c29", "metadata": {"tags": []}, "outputs": [], "source": "df = df.dropDuplicates()"}, {"cell_type": "code", "execution_count": 33, "id": "6088a8b7-a58f-404a-8207-684b7b4f42aa", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.functions import split, col\n\n# Split the 'product_name' column by the specified special characters or words (comma, &, ., or, and, (, {)\ndf = df.withColumn('product_name', \n                  split(col('product_name'), r\"[,\\.&\\(\\{|]|(?=\\s*(?:or|and))\").getItem(0))\n"}, {"cell_type": "code", "execution_count": 34, "id": "e3d4b3b3-3233-47c3-b896-ed463888f7d3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 22:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|        product_name|\n+--------------------+\n|LOHAYA Voice Assi...|\n+--------------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Get the unique values from the 'product_name' column\ndf.select('product_name').distinct().show(1)\n"}, {"cell_type": "code", "execution_count": 35, "id": "2cbb9911-636b-4253-9af7-636999855036", "metadata": {"tags": []}, "outputs": [], "source": "# Split the 'category' column by the '|' character and extract the first part\ndf = df.withColumn('category', \n                  split(col('category'), r'\\|').getItem(0))"}, {"cell_type": "code", "execution_count": 36, "id": "69b0740e-74df-4708-ae96-fb06ac220886", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.functions import regexp_extract\n\n# Extract the numeric value (integer or float) from the 'discounted_price' column\ndf = df.withColumn('discounted_price', \n                  regexp_extract(col('discounted_price'), r'(\\d+(\\.\\d+)?)', 0).cast('float'))"}, {"cell_type": "code", "execution_count": 37, "id": "5049063d-f960-4adb-aef7-7c9454dbe073", "metadata": {"tags": []}, "outputs": [], "source": "# Extract the numeric value (integer or float) from the 'actual_price' column\ndf = df.withColumn('actual_price', \n                  regexp_extract(col('actual_price'), r'(\\d+(\\.\\d+)?)', 0).cast('float'))"}, {"cell_type": "code", "execution_count": 38, "id": "8f69c342-b384-444b-8b9f-ad250a3d43d9", "metadata": {"tags": []}, "outputs": [], "source": "# Extract the numeric value (integer or float) from the 'discount_percentage' column\ndf = df.withColumn('discount_percentage', \n                  regexp_extract(col('discount_percentage'), r'(\\d+(\\.\\d+)?)', 0).cast('float'))"}, {"cell_type": "code", "execution_count": 43, "id": "7f724990-23a7-4504-889b-016811d3e811", "metadata": {"tags": []}, "outputs": [], "source": "# Remove rows where 'rating' column has the invalid value '|'\ndf = df.filter(col('rating') != '|')"}, {"cell_type": "code", "execution_count": 45, "id": "62531418-11e4-4719-82ba-a12440e7c6fe", "metadata": {"tags": []}, "outputs": [], "source": "df = df.withColumn('rating', col('rating').cast('float'))"}, {"cell_type": "code", "execution_count": 46, "id": "5c38f962-70d0-4250-9ac1-226ff971c64f", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.functions import regexp_replace\n\n# Remove commas from 'rating_count' column and preserve non-empty valid values\ndf = df.withColumn('rating_count', \n                  regexp_replace(col('rating_count'), ',', ''))\n\n# Convert the 'rating_count' column to integer\ndf = df.withColumn('rating_count', col('rating_count').cast('int'))"}, {"cell_type": "markdown", "id": "1b4130f7-3d4e-41d7-9e23-1ba68f7d1dfa", "metadata": {}, "source": "## Transformed data"}, {"cell_type": "code", "execution_count": 47, "id": "9b238bcf-a694-406b-8447-6f20b63ed701", "metadata": {"tags": []}, "outputs": [], "source": "# Drop columns from the DataFrame\ndf = df.drop('user_id', 'user_name', 'review_id', 'review_title', 'review_content', \n             'img_link', 'product_link', 'about_product')"}, {"cell_type": "code", "execution_count": 56, "id": "2115b8b2-756a-41f8-ae16-91b59ba75b92", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.window import Window\n\n# Generate sequential 'id' using row_number()\n\nwindow_spec = Window.orderBy(F.lit(1))  # Window specification for sequential order\n\ndf = df.withColumn('id', F.row_number().over(window_spec))"}, {"cell_type": "code", "execution_count": 57, "id": "5ff5b047-ae5f-48c5-8f26-bfb51d6b9004", "metadata": {"tags": []}, "outputs": [], "source": "df = df.select('id','product_id','product_name','category','discounted_price','actual_price','discount_percentage','rating','rating_count')"}, {"cell_type": "code", "execution_count": 58, "id": "36f94d64-84ea-4c4c-b6d3-0da3811c7e51", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: integer (nullable = false)\n |-- product_id: string (nullable = true)\n |-- product_name: string (nullable = true)\n |-- category: string (nullable = true)\n |-- discounted_price: float (nullable = true)\n |-- actual_price: float (nullable = true)\n |-- discount_percentage: float (nullable = true)\n |-- rating: float (nullable = true)\n |-- rating_count: integer (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "markdown", "id": "804c5d06-fcf0-4ecf-acdf-56dcddb08eab", "metadata": {}, "source": "## Data Modelling: fact_table & dimention table"}, {"cell_type": "code", "execution_count": 61, "id": "06a83c85-9c4c-4a17-a924-b5cac0eb8122", "metadata": {"tags": []}, "outputs": [], "source": "# Select specific columns from the DataFrame as product_dim dimention table\n\nproduct_dim = df.select('id', 'product_id', 'product_name', 'category')"}, {"cell_type": "code", "execution_count": 64, "id": "aa10272f-5a59-46fb-8447-6317dda15563", "metadata": {"tags": []}, "outputs": [], "source": "# Drop the specified columns and add 'id' column\n\nfact_table = df.drop('product_id', 'product_name', 'category')"}, {"cell_type": "code", "execution_count": 65, "id": "9fa3fd8d-5b5b-4306-a87f-770816f4946f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/11/19 11:25:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "+---+----------------+------------+-------------------+------+------------+\n| id|discounted_price|actual_price|discount_percentage|rating|rating_count|\n+---+----------------+------------+-------------------+------+------------+\n|  1|           199.0|       999.0|               80.0|   3.1|           2|\n|  2|           379.0|       999.0|               62.0|   4.3|        3096|\n|  3|           299.0|       799.0|               63.0|   4.2|        2117|\n|  4|           599.0|         1.0|               57.0|   4.1|       14560|\n|  5|           999.0|         1.0|               38.0|   4.3|       12093|\n|  6|           539.0|       720.0|               25.0|   4.1|       36017|\n|  7|           559.0|         1.0|               45.0|   4.1|       17325|\n|  8|             1.0|         4.0|               71.0|   3.6|          63|\n|  9|           699.0|         1.0|               59.0|   4.1|        3524|\n| 10|           599.0|         1.0|               60.0|   4.1|      161679|\n| 11|           799.0|         1.0|               60.0|   4.3|          70|\n| 12|           139.0|       249.0|               44.0|   4.0|        9378|\n| 13|           339.0|       999.0|               66.0|   4.3|        6255|\n| 14|           599.0|       999.0|               40.0|   4.1|      192587|\n| 15|            15.0|        21.0|               27.0|   4.2|       34899|\n| 16|             1.0|         7.0|               85.0|   3.6|       25910|\n| 17|             5.0|        13.0|               58.0|   4.2|        6398|\n| 18|           655.0|         1.0|               40.0|   3.2|         285|\n| 19|             2.0|         2.0|               17.0|   4.1|        3156|\n| 20|             6.0|        15.0|               59.0|   4.1|        3233|\n+---+----------------+------------+-------------------+------+------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "24/11/19 11:25:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:25:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"}, {"name": "stdout", "output_type": "stream", "text": "+---+----------+--------------------+--------------------+\n| id|product_id|        product_name|            category|\n+---+----------+--------------------+--------------------+\n|  1|B0B3JSWG81|              NGI St|        Home&Kitchen|\n|  2|B07GMFY9QM|SOFLIN Egg Boiler...|        Home&Kitchen|\n|  3|B07924P3C5|                  St|Computers&Accesso...|\n|  4|B07QCWY5XV|Mobilife Bluetoot...|         Electronics|\n|  5|B07KRCW6LZ|TP-Link Nano AC60...|Computers&Accesso...|\n|  6|B00ABMASXG|Bajaj Immersion R...|        Home&Kitchen|\n|  7|B01N6IJG0F|                   M|        Home&Kitchen|\n|  8|B08T8KWNQ9|TE\u2122 Instant Elect...|        Home&Kitchen|\n|  9|B01CS4A5V4|               Monit|        Home&Kitchen|\n| 10|B07S9S86BF|boAt Bassheads 24...|         Electronics|\n| 11|B0BPBXNQQT|Room Heater Warme...|        Home&Kitchen|\n| 12|B09NKZXMWJ|               Flix |Computers&Accesso...|\n| 13|B081FG1QYX|Wayona Type C Cab...|Computers&Accesso...|\n| 14|B01DEWVZ2C|JBL C100SI Wired ...|         Electronics|\n| 15|B09Q5SWVBJ|      OnePlus 80 cm |         Electronics|\n| 16|B08CFCK6CW|Boult Audio Trueb...|         Electronics|\n| 17|B097R45BH8|Bajaj New Shakti ...|        Home&Kitchen|\n| 18|B08RX8G496|\"LRIPL Mi Remote ...|         Electronics|\n| 19|B098QXR9X2|Ambrane 27000mAh ...|         Electronics|\n| 20|B097R3XH9R|Bajaj New Shakti ...|        Home&Kitchen|\n+---+----------+--------------------+--------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "fact_table.show()\nproduct_dim.show()"}, {"cell_type": "markdown", "id": "c533f466-3de2-481c-b88d-8c9a8e7af101", "metadata": {}, "source": "# Exporting to BigQuery"}, {"cell_type": "code", "execution_count": 66, "id": "338f16fb-f652-4e3e-9b35-e054becfca79", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/11/19 11:26:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:21 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n24/11/19 11:26:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n                                                                                \r"}], "source": "# Export DataFrame to BigQuery\nfact_table.write \\\n    .format(\"bigquery\") \\\n    .option(\"temporaryGcsBucket\", \"gs://amazon-data-analysis/temp\") \\\n    .option(\"table\", \"uber-data-analysis-442008.amazon_data.fact_table\") \\\n    .save()\n\nproduct_dim.write \\\n    .format(\"bigquery\") \\\n    .option(\"temporaryGcsBucket\", \"gs://amazon-data-analysis/temp\") \\\n    .option(\"table\", \"uber-data-analysis-442008.amazon_data.product_dim\") \\\n    .save()"}, {"cell_type": "code", "execution_count": null, "id": "604eedd6-4e06-43a7-8663-77aa3b4ece21", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}